{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21nD9sQy1RKY"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zGbvuPVl0mhC",
    "outputId": "9c46c565-6a65-4c23-a2aa-edfc577cb17b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WSuC52g1g_L"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "colab_type": "code",
    "id": "bV3A_zHQ0mhI",
    "outputId": "b6b99f86-0e94-4f9f-d3c0-8c119a3542a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp1</th>\n",
       "      <th>lp1</th>\n",
       "      <th>wp2</th>\n",
       "      <th>lp2</th>\n",
       "      <th>wp3</th>\n",
       "      <th>lp3</th>\n",
       "      <th>wp4</th>\n",
       "      <th>lp4</th>\n",
       "      <th>wp5</th>\n",
       "      <th>lp5</th>\n",
       "      <th>wp6</th>\n",
       "      <th>lp6</th>\n",
       "      <th>wp7</th>\n",
       "      <th>lp7</th>\n",
       "      <th>wp8</th>\n",
       "      <th>lp8</th>\n",
       "      <th>wp9</th>\n",
       "      <th>lp9</th>\n",
       "      <th>wp10</th>\n",
       "      <th>lp10</th>\n",
       "      <th>wp11</th>\n",
       "      <th>lp11</th>\n",
       "      <th>wp12</th>\n",
       "      <th>lp12</th>\n",
       "      <th>wp13</th>\n",
       "      <th>lp13</th>\n",
       "      <th>wp14</th>\n",
       "      <th>lp14</th>\n",
       "      <th>wn1</th>\n",
       "      <th>ln1</th>\n",
       "      <th>wn2</th>\n",
       "      <th>ln2</th>\n",
       "      <th>wn3</th>\n",
       "      <th>ln3</th>\n",
       "      <th>wn4</th>\n",
       "      <th>ln4</th>\n",
       "      <th>wn5</th>\n",
       "      <th>ln5</th>\n",
       "      <th>wn6</th>\n",
       "      <th>ln6</th>\n",
       "      <th>wn7</th>\n",
       "      <th>ln7</th>\n",
       "      <th>wn8</th>\n",
       "      <th>ln8</th>\n",
       "      <th>wn9</th>\n",
       "      <th>ln9</th>\n",
       "      <th>wn10</th>\n",
       "      <th>ln10</th>\n",
       "      <th>wn11</th>\n",
       "      <th>ln11</th>\n",
       "      <th>wn12</th>\n",
       "      <th>ln12</th>\n",
       "      <th>wn13</th>\n",
       "      <th>ln13</th>\n",
       "      <th>wn14</th>\n",
       "      <th>ln14</th>\n",
       "      <th>delay_lh_nodeaco</th>\n",
       "      <th>delay_hl_nodeaco</th>\n",
       "      <th>delay_lh_nodebco</th>\n",
       "      <th>delay_hl_nodebco</th>\n",
       "      <th>delay_hl_nodecco</th>\n",
       "      <th>delay_lh_nodecco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>7.100000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>8.000000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.500000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.600000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>6.100000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.900000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>1.100000e-07</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>9.700000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>9.200000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.500000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>8.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>1.180000e-07</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>5.400000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>6.200000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>6.100000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>3.700000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>8.400000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>4.800000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>9.600000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>8.600000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>4.600000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>1.110000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.522120e-11</td>\n",
       "      <td>3.173040e-11</td>\n",
       "      <td>2.226566e-11</td>\n",
       "      <td>3.462740e-11</td>\n",
       "      <td>3.342622e-11</td>\n",
       "      <td>2.337032e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.500000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>9.800000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.020000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.170000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>4.600000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>3.500000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>6.900000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.080000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>5.600000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.090000e-07</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>5.600000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>7.300000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.040000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>9.500000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>5.500000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>8.400000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.090000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>7.900000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>1.200000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>8.200000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>1.170000e-07</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.900000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.600000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>5.238899e-11</td>\n",
       "      <td>3.799978e-11</td>\n",
       "      <td>5.539780e-11</td>\n",
       "      <td>2.192646e-11</td>\n",
       "      <td>3.488078e-11</td>\n",
       "      <td>5.494923e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.100000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>9.400000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>7.000000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>9.300000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>8.800000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.040000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>6.000000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>6.700000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>8.100000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.400000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>5.700000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.100000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>5.700000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.110000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.900000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>1.060000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>9.700000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.960059e-11</td>\n",
       "      <td>5.370349e-11</td>\n",
       "      <td>3.837178e-11</td>\n",
       "      <td>2.275030e-11</td>\n",
       "      <td>4.715514e-11</td>\n",
       "      <td>4.289461e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>3.400000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.800000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.120000e-07</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>1.040000e-07</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.130000e-07</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>5.900000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.130000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.900000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.100000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>8.700000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>4.200000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.400000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>6.700000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>9.300000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>7.800000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.040000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>1.200000e-07</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.751387e-11</td>\n",
       "      <td>6.390787e-11</td>\n",
       "      <td>7.703473e-11</td>\n",
       "      <td>4.169431e-11</td>\n",
       "      <td>4.903933e-11</td>\n",
       "      <td>7.545821e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.500000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.070000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.700000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>9.300000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.070000e-07</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>8.200000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>1.180000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>1.150000e-07</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>7.500000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>8.600000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>6.700000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.400000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>8.200000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>9.904721e-11</td>\n",
       "      <td>5.184471e-11</td>\n",
       "      <td>9.119123e-11</td>\n",
       "      <td>7.748332e-11</td>\n",
       "      <td>5.127281e-11</td>\n",
       "      <td>8.697091e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>8.400000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>5.500000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>9.900000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>5.700000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>5.900000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>3.400000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>5.600000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.400000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>1.140000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>8.900000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>8.600000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>1.180000e-07</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.180000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>7.700000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>6.000000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.140000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>6.132782e-11</td>\n",
       "      <td>6.068520e-11</td>\n",
       "      <td>6.618706e-11</td>\n",
       "      <td>4.459739e-11</td>\n",
       "      <td>4.051638e-11</td>\n",
       "      <td>6.051959e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.400000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>1.120000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>9.600000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>8.900000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>1.120000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>4.800000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.200000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>9.100000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>4.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>9.800000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>8.900000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.200000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.130000e-07</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>3.300000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.900000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>8.500000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.200000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.700000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.130000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>3.300000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>4.000000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>5.537206e-11</td>\n",
       "      <td>5.628615e-11</td>\n",
       "      <td>5.637663e-11</td>\n",
       "      <td>4.953495e-11</td>\n",
       "      <td>5.434270e-11</td>\n",
       "      <td>5.769249e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.900000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>9.400000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>9.300000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>1.010000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.100000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>1.120000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.180000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.600000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>5.300000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.900000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.190000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>6.100000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>4.200000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.600000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>4.800000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>3.500000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>7.500000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>3.600000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>4.200000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>9.200000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>4.600000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.331194e-11</td>\n",
       "      <td>2.265441e-11</td>\n",
       "      <td>3.116825e-11</td>\n",
       "      <td>2.106438e-11</td>\n",
       "      <td>4.404206e-11</td>\n",
       "      <td>3.341765e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.060000e-07</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>1.110000e-07</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>6.000000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>6.300000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.100000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.170000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>4.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>8.600000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>8.100000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>7.200000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>7.200000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>4.500000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>6.900000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.180000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>5.900000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>1.100000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>7.300000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>9.500000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>3.600000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>4.086251e-11</td>\n",
       "      <td>4.671212e-11</td>\n",
       "      <td>4.381628e-11</td>\n",
       "      <td>6.214009e-11</td>\n",
       "      <td>4.908137e-11</td>\n",
       "      <td>4.541611e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>8.200000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>1.190000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>6.200000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.400000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>8.700000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>8.800000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>9.200000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>6.700000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>6.200000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>1.150000e-07</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>1.090000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>3.800000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>6.100000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>5.300000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.703502e-11</td>\n",
       "      <td>7.088777e-11</td>\n",
       "      <td>3.620041e-11</td>\n",
       "      <td>6.290361e-11</td>\n",
       "      <td>5.835766e-11</td>\n",
       "      <td>3.650906e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            wp1           lp1  ...  delay_hl_nodecco  delay_lh_nodecco\n",
       "0  1.050000e-07  2.300000e-08  ...      3.342622e-11      2.337032e-11\n",
       "1  7.400000e-08  2.700000e-08  ...      3.488078e-11      5.494923e-11\n",
       "2  6.500000e-08  2.800000e-08  ...      4.715514e-11      4.289461e-11\n",
       "3  3.500000e-08  3.200000e-08  ...      4.903933e-11      7.545821e-11\n",
       "4  9.500000e-08  2.700000e-08  ...      5.127281e-11      8.697091e-11\n",
       "5  3.000000e-08  3.200000e-08  ...      4.051638e-11      6.051959e-11\n",
       "6  8.400000e-08  2.500000e-08  ...      5.434270e-11      5.769249e-11\n",
       "7  7.900000e-08  2.500000e-08  ...      4.404206e-11      3.341765e-11\n",
       "8  1.060000e-07  2.500000e-08  ...      4.908137e-11      4.541611e-11\n",
       "9  3.800000e-08  2.800000e-08  ...      5.835766e-11      3.650906e-11\n",
       "\n",
       "[10 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel(\"Delays_W_L_FAMIRRORSimulated_50K.xlsx\")\n",
    "dataset=df.values\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBBtecnZ1k1F"
   },
   "source": [
    "## Training and testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "WncOlfxU0mhP",
    "outputId": "d738053f-1113-4381-edf8-4b5e83256ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0098\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.9731e-04\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 5.4771e-04\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.8754e-04\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 4.3072e-04\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.1178e-04\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.9868e-04\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.5596e-04\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.5606e-04\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.5151e-04\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 3.4961e-04\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 3.2943e-04\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.2378e-04\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.0824e-04\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.0890e-04\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.7839e-04\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.4516e-04\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.7786e-04\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.7226e-04\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.5640e-04\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 1.3590e-04\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.1973e-04\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.0490e-04\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0200e-04\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 8.9082e-05\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 9.1859e-05\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 8.1327e-05\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 7.9516e-05\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.8438e-05\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.1268e-05\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.0739e-05\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.9541e-05\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.9906e-05\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 5.5973e-05\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 5.2421e-05\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 5.1092e-05\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 4.6252e-05\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 4.6897e-05\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.1950e-05\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.9290e-05\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.2005e-05\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 3.6054e-05\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.1424e-05\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.4351e-05\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.7645e-05\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 3.5474e-05\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.6676e-05\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.3495e-05\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 3.3379e-05\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 3.5289e-05\n",
      "output variable 56\n",
      "Train R2 Score: 0.9989093433268265\n",
      "Test R2 Score: 0.998864835186604\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 0.0060\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 0.0025\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0016\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 0.0010\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.4011e-04\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.5148e-04\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.7051e-04\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.4836e-04\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.2118e-04\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.0639e-04\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.9605e-04\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.7791e-04\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7360e-04\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.6064e-04\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.5997e-04\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.5497e-04\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.4900e-04\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.4835e-04\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 1.4187e-04\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.3159e-04\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.3076e-04\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.4232e-04\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.2813e-04\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.3208e-04\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.2425e-04\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.2461e-04\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.2358e-04\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 1.2327e-04\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.1930e-04\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.1342e-04\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0433e-04\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 9.8428e-05\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 9.0813e-05\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 9.0538e-05\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 8.7116e-05\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 8.3665e-05\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 8.4185e-05\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.9661e-05\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 7.8400e-05\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 7.7040e-05\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.7168e-05\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.7784e-05\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 7.4931e-05\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.3691e-05\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 7.3620e-05\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 7.2674e-05\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 6.7957e-05\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.9301e-05\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.8006e-05\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.9644e-05\n",
      "output variable 57\n",
      "Train R2 Score: 0.9911632452531464\n",
      "Test R2 Score: 0.9905799291898839\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0101\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 9.1235e-04\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.7252e-04\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 4.0944e-04\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.7070e-04\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.6100e-04\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.3185e-04\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.3544e-04\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.2526e-04\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.7279e-04\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 2.2952e-04\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 2.0151e-04\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 1.8117e-04\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.9138e-04\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.7933e-04\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.6390e-04\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4691e-04\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.4169e-04\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4044e-04\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.3717e-04\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0838e-04\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 9.3616e-05\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 8.7392e-05\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 8.5612e-05\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 8.4326e-05\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 7.8193e-05\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.7401e-05\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.7702e-05\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.7262e-05\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.5331e-05\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 6.7590e-05\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 6.8619e-05\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 5.6330e-05\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.8374e-05\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 5.1868e-05\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.6709e-05\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.1730e-05\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 4.9813e-05\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 4.7641e-05\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.5637e-05\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.8990e-05\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.6088e-05\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.4808e-05\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.3658e-05\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.8529e-05\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.4871e-05\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.5139e-05\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 3.1923e-05\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.1399e-05\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 3.1015e-05\n",
      "output variable 58\n",
      "Train R2 Score: 0.99928133175891\n",
      "Test R2 Score: 0.9992330723115311\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0096\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0036\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 0.0023\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 0.0019\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0017\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 9.5144e-04\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.8877e-04\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.2457e-04\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.8800e-04\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.7494e-04\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 2.5970e-04\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.3986e-04\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.3362e-04\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.1291e-04\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 2.0567e-04\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.0005e-04\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.8848e-04\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.8282e-04\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.6305e-04\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.6035e-04\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 1.5080e-04\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.4468e-04\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.3868e-04\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.2526e-04\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.1894e-04\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.0918e-04\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.0654e-04\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 9.7126e-05\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 9.0962e-05\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 8.7418e-05\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 9.0746e-05\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 8.3327e-05\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 8.2175e-05\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.8596e-05\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.4277e-05\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.4079e-05\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.3563e-05\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.9160e-05\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.8281e-05\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 6.9847e-05\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 6.5142e-05\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 6.6512e-05\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 6.3488e-05\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 6.1302e-05\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 6.1212e-05\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 6.3735e-05\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 5.9445e-05\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 5.7089e-05\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 5.7419e-05\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.7262e-05\n",
      "output variable 59\n",
      "Train R2 Score: 0.9957031200815989\n",
      "Test R2 Score: 0.9953489853760432\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 0.0059\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 0.0025\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 0.0015\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 9.6960e-04\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 4.5424e-04\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 2.6799e-04\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.4148e-04\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.2253e-04\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.9607e-04\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.7675e-04\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.5137e-04\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.5487e-04\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.3815e-04\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.3471e-04\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 1.3284e-04\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.2859e-04\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.1990e-04\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.1829e-04\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.1827e-04\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 1.1104e-04\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.0574e-04\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0252e-04\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0297e-04\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0011e-04\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 9.5741e-05\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 9.1865e-05\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 8.7744e-05\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 8.6007e-05\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 8.1422e-05\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 7.8867e-05\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 7.7731e-05\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 7.6757e-05\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.8611e-05\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 7.1473e-05\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.6488e-05\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 6.5751e-05\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 6.3512e-05\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.1515e-05\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 6.4165e-05\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 5.7024e-05\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 6.4651e-05\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 5.8133e-05\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 5.8360e-05\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 5.7436e-05\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 2s 53us/step - loss: 5.4652e-05\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 2s 48us/step - loss: 5.5322e-05\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 2s 60us/step - loss: 5.6507e-05\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 2s 51us/step - loss: 5.5488e-05\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 2s 46us/step - loss: 5.1867e-05\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 5.0815e-05\n",
      "output variable 60\n",
      "Train R2 Score: 0.9966128142059566\n",
      "Test R2 Score: 0.9962073632460067\n",
      "Epoch 1/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 0.0090\n",
      "Epoch 2/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.3364e-04\n",
      "Epoch 3/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 4.1206e-04\n",
      "Epoch 4/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.6353e-04\n",
      "Epoch 5/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.2506e-04\n",
      "Epoch 6/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 3.1787e-04\n",
      "Epoch 7/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.9008e-04\n",
      "Epoch 8/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.8247e-04\n",
      "Epoch 9/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 2.6210e-04\n",
      "Epoch 10/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 2.5824e-04\n",
      "Epoch 11/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 2.4666e-04\n",
      "Epoch 12/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.4008e-04\n",
      "Epoch 13/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 2.3468e-04\n",
      "Epoch 14/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 2.2193e-04\n",
      "Epoch 15/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.9440e-04\n",
      "Epoch 16/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.4225e-04\n",
      "Epoch 17/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.3228e-04\n",
      "Epoch 18/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.2196e-04\n",
      "Epoch 19/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.0067e-04\n",
      "Epoch 20/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.8762e-05\n",
      "Epoch 21/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.7993e-05\n",
      "Epoch 22/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 7.4184e-05\n",
      "Epoch 23/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 6.6553e-05\n",
      "Epoch 24/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.6795e-05\n",
      "Epoch 25/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.5892e-05\n",
      "Epoch 26/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.3939e-05\n",
      "Epoch 27/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 6.0960e-05\n",
      "Epoch 28/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 5.8686e-05\n",
      "Epoch 29/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 5.6373e-05\n",
      "Epoch 30/50\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 5.6317e-05\n",
      "Epoch 31/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.6762e-05\n",
      "Epoch 32/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 5.3659e-05\n",
      "Epoch 33/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.0437e-05\n",
      "Epoch 34/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.8243e-05\n",
      "Epoch 35/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 5.1282e-05\n",
      "Epoch 36/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 4.8256e-05\n",
      "Epoch 37/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 4.9697e-05\n",
      "Epoch 38/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 4.6897e-05\n",
      "Epoch 39/50\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 4.4435e-05\n",
      "Epoch 40/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.3605e-05\n",
      "Epoch 41/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 4.3794e-05\n",
      "Epoch 42/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 4.0532e-05\n",
      "Epoch 43/50\n",
      "40000/40000 [==============================] - 1s 37us/step - loss: 4.1419e-05\n",
      "Epoch 44/50\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 3.9044e-05\n",
      "Epoch 45/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.9162e-05\n",
      "Epoch 46/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.5955e-05\n",
      "Epoch 47/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.6759e-05\n",
      "Epoch 48/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.6237e-05\n",
      "Epoch 49/50\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 3.8614e-05\n",
      "Epoch 50/50\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 3.4158e-05\n",
      "output variable 61\n",
      "Train R2 Score: 0.9989880289996343\n",
      "Test R2 Score: 0.9989508700714952\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "scalarX = []\n",
    "scalarY = []\n",
    "\n",
    "for output in range(56, 62):\n",
    "\n",
    "  X = dataset[:40000,0:56]\n",
    "  y = dataset[:40000,output]\n",
    "\n",
    "  scalarX.append(MinMaxScaler()) \n",
    "  scalarY.append(MinMaxScaler())\n",
    "  \n",
    "  scalarX[output-56].fit(X)\n",
    "  scalarY[output-56].fit(y.reshape(40000,1))\n",
    "  \n",
    "  X = scalarX[output-56].transform(X)\n",
    "  y = scalarY[output-56].transform(y.reshape(40000,1))\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(38, input_dim=56, activation='relu'))\n",
    "  model.add(Dense(26, activation='relu'))\n",
    "  model.add(Dense(1, activation='linear'))\n",
    "  model.compile(loss='mse', optimizer='adam')\n",
    "  model.fit(X, y, epochs=50, verbose=1)\n",
    "\n",
    "  model_list.append(clone_model(model))\n",
    "\n",
    "  X_test = dataset[40000:,0:56]\n",
    "  y_test = dataset[40000:,output]\n",
    "  X_test = scalarX[output-56].transform(X_test)\n",
    "  y_test = scalarY[output-56].transform(y_test.reshape(10000,1))\n",
    "\n",
    "  y_trainpred = model.predict(X)\n",
    "  y_trainpred2 = scalarY[output-56].inverse_transform(y_trainpred)\n",
    "\n",
    "  y_testpred = model.predict(X_test)\n",
    "  y_testpred2 = scalarY[output-56].inverse_transform(y_testpred)\n",
    "\n",
    "  y_test2 = scalarY[output-56].inverse_transform(y_test)\n",
    "  y_2 = scalarY[output-56].inverse_transform(y)\n",
    "\n",
    "  r2_train = r2_score(y_trainpred2, y_2)\n",
    "  r2_test = r2_score(y_testpred2, y_test2)\n",
    "\n",
    "  print(\"output variable\", output)\n",
    "  print(\"Train R2 Score: \"+str(r2_train))\n",
    "  print(\"Test R2 Score: \"+str(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyS35cG_9Ukj"
   },
   "source": [
    "## Converging to minima using genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GqbareL99SvE"
   },
   "outputs": [],
   "source": [
    "seed_data = dataset[0,0:56].tolist() #->changed from overfit\n",
    "\n",
    "GENE_LEN = len(seed_data)\n",
    "ULIM_COEFF = 0.001\n",
    "LLIM_COEFF = 0.0\n",
    "POPULATION_SIZE = 10 # keep it even\n",
    "step = 10**(-1)\n",
    "ALLOWED_ACCESS = 2000 # access to model\n",
    "ELITE_COUNT = int( POPULATION_SIZE * 0.2)\n",
    "CROSS_COUNT = POPULATION_SIZE - ELITE_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24eQAncA-JZE"
   },
   "outputs": [],
   "source": [
    "def give_order(num):\n",
    "\t'''\n",
    "\treturns the order of magnitude of number given\n",
    "\t'''\n",
    "\tnum = abs(num)\n",
    "\n",
    "\tif num == 0.0:\n",
    "\t\torder = 0\n",
    "\telif num >= 1.0:\n",
    "\t\tn = int(num)\n",
    "\t\torder = -1\n",
    "\t\twhile n > 0:\n",
    "\t\t\tn = int(n/10)\n",
    "\t\t\torder += 1\n",
    "\telse:\n",
    "\t\torder = 0\n",
    "\t\twhile num < 1.0:\n",
    "\t\t\tnum *= 10\n",
    "\t\t\torder -= 1\n",
    "\treturn order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mzP1vNCi-Qlr"
   },
   "outputs": [],
   "source": [
    "def mutate(num):\n",
    "\t'''\n",
    "\tnum is number to mutate\n",
    "\tstep is magnitude by which to mutate\n",
    "\t'''\n",
    "\tr = (random.random() - 0.5) * 2.0 # generates number [-1.0, 1.0]\n",
    "\tr *= step * 10**give_order(num)\n",
    "\tr += num\n",
    "\n",
    "\tif r > ULIM_COEFF:\n",
    "\t\treturn ULIM_COEFF\n",
    "\telif r < LLIM_COEFF:\n",
    "\t\treturn LLIM_COEFF\n",
    "\telse:\n",
    "\t\treturn r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3HiHa79r-UDW"
   },
   "outputs": [],
   "source": [
    "def calculate_fitness(x):\n",
    "\t'''\n",
    "\tLower fitness value => more fit.\n",
    "\tFittest at value 0.\n",
    "\t'''\n",
    "\tfitness_weights = [+1.0, +1.0, +1.0, +1.0, +1.0, +1.0]\n",
    "  \n",
    "\tx = np.array(x)\n",
    "\tx = np.expand_dims(x, axis=0)\n",
    "\ty_pred = 0\n",
    "\tfor i in range(6):\n",
    "\t\txt = scalarX[i].transform(x)\n",
    "\t\tyt = model_list[i].predict(xt)\n",
    "\t\ty_pred += fitness_weights[i] * scalarY[i].inverse_transform(yt).item()\n",
    "\t\n",
    "\treturn y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11Fti9H9-X2l"
   },
   "outputs": [],
   "source": [
    "def calculate_rank(f):\n",
    "\t'''\n",
    "\tf is fitness\n",
    "\tsf is sorted fitness\n",
    "\tr contains ranks of f\n",
    "\t'''\n",
    "\tsf = sorted(f)\n",
    "\tr = [] # ranks\n",
    "\tfor i in f:\n",
    "\t\trnum = sf.index(i)\n",
    "\t\twhile rnum in r: # To avoid duplicate ranks\n",
    "\t\t\trnum += 1\n",
    "\t\tr.append(rnum)\n",
    "\treturn r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJnFRzPD-bDK"
   },
   "outputs": [],
   "source": [
    "def initial_population():\n",
    "\t'''\n",
    "\tp is population\n",
    "\t'''\n",
    "\tmutation_probability = 0.4 # TUNE\n",
    "\tp = []\n",
    "\tp.append(seed_data)\n",
    "\tfor i in range(POPULATION_SIZE-1):\n",
    "\t\tgene = seed_data[:]\n",
    "\t\tfor i in range(GENE_LEN):\n",
    "\t\t\tif random.random() < mutation_probability:\n",
    "\t\t\t\tgene[i] = mutate(gene[i])\n",
    "\t\tp.append(gene)\n",
    "\treturn p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hXX22mj-elw"
   },
   "outputs": [],
   "source": [
    "def calculate_chance(r, p):\n",
    "\t'''\n",
    "\tr is rank\n",
    "\tpop is population\n",
    "\t'''\n",
    "\tpc = 0.30\n",
    "\tc = []\n",
    "\tfor i in range(POPULATION_SIZE):\n",
    "\t\tc.append(pc * (1-pc)**r[i])\n",
    "\treturn c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lk76IY_-f5e"
   },
   "outputs": [],
   "source": [
    "def select_population(pop, c):\n",
    "\t'''\n",
    "\tpop is population\n",
    "\tc is chance\n",
    "\t'''\n",
    "\treturn random.choices(pop, c, k=CROSS_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rxNV6r1B-l8X"
   },
   "outputs": [],
   "source": [
    "def do_crossover(s):\n",
    "\t'''\n",
    "\ts is selected population\n",
    "\tco is crossover\n",
    "\tp parent\n",
    "\tc child\n",
    "\t'''\n",
    "\tco = []\n",
    "\tfor i in range(CROSS_COUNT):\n",
    "\t\tp1 = s[(i+0) % CROSS_COUNT]\n",
    "\t\tp2 = s[(i+1) % CROSS_COUNT]\n",
    "\t\tc = []\n",
    "\t\tfor j in range(GENE_LEN):\n",
    "\t\t\tif random.random() < 0.5:\n",
    "\t\t\t\tc.append(p1[j])\n",
    "\t\t\telse:\n",
    "\t\t\t\tc.append(p2[j])\n",
    "\t\tco.append(c)\n",
    "\n",
    "\treturn co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnPcJNXn-qkL"
   },
   "outputs": [],
   "source": [
    "def do_mutation(c):\n",
    "\t'''\n",
    "\tc is cross\n",
    "\tmc is mutated cross\n",
    "\tmg is mutated gene\n",
    "\t'''\n",
    "\tmutation_probability = 0.15\n",
    "\n",
    "\tmc = []\n",
    "\tfor gene in c:\n",
    "\t\tmg = []\n",
    "\t\tfor i in gene:\n",
    "\t\t\tif random.random() <= mutation_probability:\n",
    "\t\t\t\tmg.append(mutate(i))\n",
    "\t\t\telse:\n",
    "\t\t\t\tmg.append(i)\n",
    "\t\tmc.append(mg)\n",
    "\n",
    "\tglobal step\n",
    "\tstep *= 0.985 # keep less than 1.0\n",
    "\t\n",
    "\treturn mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-Bazeve-t14"
   },
   "outputs": [],
   "source": [
    "def pick_elite(population, rank):\n",
    "\telite = []\n",
    "\tcur_rank = 0 # to avoid duplicates\n",
    "\tfor i in range(ELITE_COUNT):\n",
    "\t\telite.append(population[rank.index(cur_rank)])\n",
    "\t\tcur_rank += 1\n",
    "\t\twhile(cur_rank < len(population) and population[rank.index(cur_rank)] in elite):\n",
    "\t\t\tcur_rank += 1\n",
    "\t\tif cur_rank >= len(population):\n",
    "\t\t\tcur_rank = 0 \n",
    "\treturn elite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OmrxC-J8L9KC"
   },
   "outputs": [],
   "source": [
    "def print_delays(x):\n",
    "  x = np.array(x)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  for i in range(6):\n",
    "    xt = scalarX[i].transform(x)\n",
    "    yt = model_list[i].predict(xt)\n",
    "    print('delay', i, scalarY[i].inverse_transform(yt).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SaH3E0EJ-3FV",
    "outputId": "5d448894-9d71-45e6-96f1-f12d7be82d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation = 1  fitness = 1.5422494271249976e-10\n",
      "generation = 2  fitness = 1.481489826649085e-10\n",
      "generation = 3  fitness = 1.4367155208583338e-10\n",
      "generation = 5  fitness = 1.379964259182187e-10\n",
      "generation = 6  fitness = 1.3677752160046186e-10\n",
      "generation = 7  fitness = 1.274254608080172e-10\n",
      "generation = 8  fitness = 1.210707905457964e-10\n",
      "generation = 9  fitness = 1.1968127357209202e-10\n",
      "generation = 10  fitness = 1.0130722649659418e-10\n",
      "generation = 13  fitness = 9.802459711993894e-11\n",
      "generation = 14  fitness = 8.946550271449194e-11\n",
      "generation = 15  fitness = 7.70093624286039e-11\n",
      "generation = 18  fitness = 7.253510292404286e-11\n",
      "generation = 19  fitness = 7.073496996468087e-11\n",
      "generation = 20  fitness = 6.688316393776983e-11\n",
      "generation = 21  fitness = 5.189116671078242e-11\n",
      "generation = 23  fitness = 4.733024042136158e-11\n",
      "generation = 24  fitness = 4.334700133556968e-11\n",
      "generation = 25  fitness = 3.65827229620308e-11\n",
      "generation = 27  fitness = 2.6614278489378584e-11\n",
      "generation = 29  fitness = 2.2206070315888837e-11\n",
      "generation = 30  fitness = 1.2185266684561213e-11\n",
      "generation = 32  fitness = 8.491599784443693e-12\n",
      "generation = 33  fitness = 3.710169324544488e-12\n",
      "generation = 34  fitness = 3.780083884796781e-13\n",
      "generation = 35  fitness = -4.041274259680705e-12\n",
      "generation = 36  fitness = -8.55516178732696e-12\n",
      "generation = 37  fitness = -1.5823488352939563e-11\n",
      "generation = 39  fitness = -1.8414453989423762e-11\n",
      "generation = 40  fitness = -1.9522372433911084e-11\n",
      "generation = 41  fitness = -2.7699009752524262e-11\n",
      "generation = 42  fitness = -3.4048641510409094e-11\n",
      "generation = 44  fitness = -3.860304697428374e-11\n",
      "generation = 45  fitness = -4.0571281577361784e-11\n",
      "generation = 46  fitness = -4.271186789667203e-11\n",
      "generation = 47  fitness = -4.482085015633519e-11\n",
      "generation = 48  fitness = -5.391844566313142e-11\n",
      "generation = 50  fitness = -5.805816591375468e-11\n",
      "generation = 52  fitness = -6.050316411071455e-11\n",
      "generation = 53  fitness = -6.400745341736402e-11\n",
      "generation = 54  fitness = -6.633000810933598e-11\n",
      "generation = 55  fitness = -6.879708890246417e-11\n",
      "generation = 56  fitness = -7.181249692123082e-11\n",
      "generation = 57  fitness = -7.96358658270574e-11\n",
      "generation = 59  fitness = -8.524494955405859e-11\n",
      "generation = 60  fitness = -8.832019252232037e-11\n",
      "generation = 61  fitness = -9.210219522812202e-11\n",
      "generation = 62  fitness = -9.633170650058531e-11\n",
      "generation = 63  fitness = -9.840569006359934e-11\n",
      "generation = 64  fitness = -1.0049929465016927e-10\n",
      "generation = 65  fitness = -1.0240322608975894e-10\n",
      "generation = 66  fitness = -1.0557391744679678e-10\n",
      "generation = 67  fitness = -1.0761736890085166e-10\n",
      "generation = 68  fitness = -1.0886034895784061e-10\n",
      "generation = 69  fitness = -1.1593203437174071e-10\n",
      "generation = 71  fitness = -1.2021023529352158e-10\n",
      "generation = 73  fitness = -1.2246541584645665e-10\n",
      "generation = 75  fitness = -1.2544435227992284e-10\n",
      "generation = 76  fitness = -1.276480408461851e-10\n",
      "generation = 79  fitness = -1.321443183826751e-10\n",
      "generation = 81  fitness = -1.328163225016929e-10\n",
      "generation = 82  fitness = -1.3319095399342857e-10\n",
      "generation = 83  fitness = -1.365295662983379e-10\n",
      "generation = 84  fitness = -1.3862795693276794e-10\n",
      "generation = 86  fitness = -1.4189406030359897e-10\n",
      "generation = 87  fitness = -1.4358219611366758e-10\n",
      "generation = 89  fitness = -1.465296173243022e-10\n",
      "generation = 90  fitness = -1.4709623902503348e-10\n",
      "generation = 91  fitness = -1.4827649673951164e-10\n",
      "generation = 92  fitness = -1.4981722579101436e-10\n",
      "generation = 93  fitness = -1.502379147737959e-10\n",
      "generation = 94  fitness = -1.508417781415257e-10\n",
      "generation = 95  fitness = -1.5159347681228258e-10\n",
      "generation = 96  fitness = -1.5231794276392152e-10\n",
      "generation = 97  fitness = -1.560637082347223e-10\n",
      "generation = 99  fitness = -1.5938702349052244e-10\n",
      "generation = 100  fitness = -1.595868261215598e-10\n",
      "generation = 102  fitness = -1.635303391723901e-10\n",
      "generation = 104  fitness = -1.6499688936097087e-10\n",
      "generation = 105  fitness = -1.6538533129800692e-10\n",
      "generation = 106  fitness = -1.665953735640463e-10\n",
      "generation = 107  fitness = -1.6837192165670978e-10\n",
      "generation = 108  fitness = -1.69126589903007e-10\n",
      "generation = 109  fitness = -1.7199573969922666e-10\n",
      "generation = 111  fitness = -1.734688419383762e-10\n",
      "generation = 112  fitness = -1.7424097559746998e-10\n",
      "generation = 113  fitness = -1.7544414640698058e-10\n",
      "generation = 114  fitness = -1.7670052226970157e-10\n",
      "generation = 115  fitness = -1.7704902149397184e-10\n",
      "generation = 116  fitness = -1.7912767731782797e-10\n",
      "generation = 118  fitness = -1.794233752457769e-10\n",
      "generation = 119  fitness = -1.8042672152336625e-10\n",
      "generation = 120  fitness = -1.8234868107668e-10\n",
      "generation = 123  fitness = -1.8326218754333157e-10\n",
      "generation = 124  fitness = -1.8440662560327559e-10\n",
      "generation = 125  fitness = -1.8529459260355208e-10\n",
      "generation = 126  fitness = -1.869904079666862e-10\n",
      "generation = 127  fitness = -1.882281875937447e-10\n",
      "generation = 129  fitness = -1.8939784723198683e-10\n",
      "generation = 130  fitness = -1.9096183878977713e-10\n",
      "generation = 132  fitness = -1.9211078040870522e-10\n",
      "generation = 133  fitness = -1.9440680597455906e-10\n",
      "generation = 134  fitness = -1.9570322207403124e-10\n",
      "generation = 136  fitness = -1.957158940121828e-10\n",
      "generation = 137  fitness = -1.9667217420610283e-10\n",
      "generation = 138  fitness = -1.9689487865647004e-10\n",
      "generation = 139  fitness = -1.9734098448236093e-10\n",
      "generation = 140  fitness = -1.9811200661738748e-10\n",
      "generation = 141  fitness = -1.9885578145077687e-10\n",
      "generation = 142  fitness = -2.005554927859976e-10\n",
      "generation = 143  fitness = -2.008029656181548e-10\n",
      "generation = 144  fitness = -2.012327273131359e-10\n",
      "generation = 145  fitness = -2.0214650829977754e-10\n",
      "generation = 146  fitness = -2.0318489382317728e-10\n",
      "generation = 147  fitness = -2.0365575263518731e-10\n",
      "generation = 148  fitness = -2.0542275367720075e-10\n",
      "generation = 150  fitness = -2.0636691921288586e-10\n",
      "generation = 151  fitness = -2.0648166705085347e-10\n",
      "generation = 152  fitness = -2.0816203491827445e-10\n",
      "generation = 153  fitness = -2.0872793207379892e-10\n",
      "generation = 154  fitness = -2.0901349314511597e-10\n",
      "generation = 155  fitness = -2.0959547986088012e-10\n",
      "generation = 156  fitness = -2.0989064609608366e-10\n",
      "generation = 157  fitness = -2.103648748252862e-10\n",
      "generation = 158  fitness = -2.106589225975286e-10\n",
      "generation = 159  fitness = -2.1150907024078403e-10\n",
      "generation = 160  fitness = -2.120212330355975e-10\n",
      "generation = 161  fitness = -2.1270889151610295e-10\n",
      "generation = 162  fitness = -2.129984684722669e-10\n",
      "generation = 163  fitness = -2.1333474375072325e-10\n",
      "generation = 166  fitness = -2.142544171593319e-10\n",
      "generation = 168  fitness = -2.1459445136672028e-10\n",
      "generation = 169  fitness = -2.1508954968670058e-10\n",
      "generation = 170  fitness = -2.1610843756875164e-10\n",
      "generation = 171  fitness = -2.1637187831366478e-10\n",
      "generation = 172  fitness = -2.170661504274224e-10\n",
      "generation = 173  fitness = -2.1722766012192973e-10\n",
      "generation = 174  fitness = -2.1763612179787062e-10\n",
      "generation = 175  fitness = -2.180868519628676e-10\n",
      "generation = 176  fitness = -2.187515828200315e-10\n",
      "generation = 178  fitness = -2.1936066938593735e-10\n",
      "generation = 179  fitness = -2.198873930159273e-10\n",
      "generation = 181  fitness = -2.2028475636474976e-10\n",
      "generation = 182  fitness = -2.2057462453761723e-10\n",
      "generation = 183  fitness = -2.2092486607477868e-10\n",
      "generation = 184  fitness = -2.2114461173741717e-10\n",
      "generation = 185  fitness = -2.2155105636363637e-10\n",
      "generation = 187  fitness = -2.2175454506521974e-10\n",
      "generation = 188  fitness = -2.2202374986256268e-10\n",
      "generation = 190  fitness = -2.2202528639388153e-10\n",
      "generation = 191  fitness = -2.2233983707972693e-10\n",
      "generation = 192  fitness = -2.2253691120757702e-10\n",
      "generation = 193  fitness = -2.2307048634477578e-10\n",
      "generation = 194  fitness = -2.2337767356314653e-10\n",
      "generation = 195  fitness = -2.2372541753218345e-10\n",
      "generation = 196  fitness = -2.2380905418881158e-10\n",
      "generation = 198  fitness = -2.2395078196416063e-10\n",
      "generation = 199  fitness = -2.2411659268868622e-10\n",
      "fitness and optimized input variables  [-2.2411659268868622e-10, [1.2605213170420611e-07, 2.65462351214359e-08, 7.075681594799577e-08, 2.1192338237280253e-08, 8.12045954759516e-08, 2.9368072555746835e-08, 9.528635464340517e-08, 2.5938453274115948e-08, 4.503152774529112e-08, 2.3726457272391645e-08, 6.016497154558441e-08, 2.1316671793754832e-08, 4.9553807641084856e-08, 2.807637579675941e-08, 9.777859482049084e-08, 3.081031900911527e-08, 9.734203509021448e-08, 2.1135885466071096e-08, 9.343241952616886e-08, 2.5410121046452087e-08, 8.565183042485706e-08, 2.563286178151225e-08, 8.55871125726518e-08, 3.301336947666634e-08, 1.24007485617162e-07, 1.913912403371328e-08, 5.298688461061304e-08, 3.251846402068872e-08, 6.212614064934227e-08, 2.244369611098791e-08, 6.145830254480455e-08, 2.4356178288219915e-08, 3.771389293434721e-08, 1.9125477228390285e-08, 8.348366673433703e-08, 2.6222299221298234e-08, 4.941852143996817e-08, 2.2660009826934088e-08, 6.377588815987687e-08, 1.9220718275642487e-08, 9.485982093981379e-08, 3.0306304602198515e-08, 8.58444639565178e-08, 2.846646457243956e-08, 2.8839613795697855e-08, 3.4504232459800067e-08, 2.9961984886153503e-08, 2.84413196848618e-08, 2.418373543327164e-08, 3.084982370600177e-08, 3.094759605009028e-08, 3.018199643713948e-08, 4.547545944874005e-08, 2.851843130612824e-08, 1.0670325900035931e-07, 2.4447573506574487e-08]]\n",
      "delay 0 1.0825468993447274e-10\n",
      "delay 1 -1.385271324733095e-11\n",
      "delay 2 -5.584227524835228e-11\n",
      "delay 3 -3.184525776758762e-12\n",
      "delay 4 -7.631908299776669e-11\n",
      "delay 5 -1.8317268535295028e-10\n"
     ]
    }
   ],
   "source": [
    "fitest = [float('inf'), []] # [fitness_value, genes]\n",
    "population = initial_population()\n",
    "\n",
    "generation = 1\n",
    "access_left = ALLOWED_ACCESS\n",
    "while access_left > POPULATION_SIZE:\n",
    "\tfitness = []\n",
    "\tfor i in population:\n",
    "\t\tfitness.append(calculate_fitness(i))\n",
    "\n",
    "\trank = calculate_rank(fitness[:])\t\n",
    "\t\n",
    "\t# print(fitness[rank.index(0)])\n",
    "\tif fitness[rank.index(0)] < fitest[0]:\n",
    "\t\tfitest[0] = fitness[rank.index(0)]\n",
    "\t\tfitest[1] = population[rank.index(0)][:]\n",
    "\t\tprint('generation =', generation, ' fitness =', fitest[0])\n",
    "\n",
    "\tchance = calculate_chance(rank, population)\n",
    "\tselect = select_population(population, chance)\n",
    "\tcross = do_crossover(select)\n",
    "\telite = pick_elite(population, rank)\n",
    "\tpopulation = do_mutation(cross) + elite\n",
    "\t\n",
    "\taccess_left -= POPULATION_SIZE\n",
    "\tgeneration += 1\n",
    "\n",
    "print('fitness and optimized input variables ', fitest)\n",
    "print_delays(fitest[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mini_project_framework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
