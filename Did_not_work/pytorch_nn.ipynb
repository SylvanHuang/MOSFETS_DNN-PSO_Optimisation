{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp1</th>\n",
       "      <th>lp1</th>\n",
       "      <th>wp2</th>\n",
       "      <th>lp2</th>\n",
       "      <th>wp3</th>\n",
       "      <th>lp3</th>\n",
       "      <th>wp4</th>\n",
       "      <th>lp4</th>\n",
       "      <th>wp5</th>\n",
       "      <th>lp5</th>\n",
       "      <th>...</th>\n",
       "      <th>wn13</th>\n",
       "      <th>ln13</th>\n",
       "      <th>wn14</th>\n",
       "      <th>ln14</th>\n",
       "      <th>delay_lh_nodeaco</th>\n",
       "      <th>delay_hl_nodeaco</th>\n",
       "      <th>delay_lh_nodebco</th>\n",
       "      <th>delay_hl_nodebco</th>\n",
       "      <th>delay_hl_nodecco</th>\n",
       "      <th>delay_lh_nodecco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>7.100000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>8.000000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>9.500000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.600000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>4.600000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>1.110000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.522120e-11</td>\n",
       "      <td>3.173040e-11</td>\n",
       "      <td>2.226566e-11</td>\n",
       "      <td>3.462740e-11</td>\n",
       "      <td>3.342622e-11</td>\n",
       "      <td>2.337032e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.500000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>9.800000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>1.020000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.600000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>5.238899e-11</td>\n",
       "      <td>3.799978e-11</td>\n",
       "      <td>5.539780e-11</td>\n",
       "      <td>2.192646e-11</td>\n",
       "      <td>3.488078e-11</td>\n",
       "      <td>5.494923e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.500000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.100000e-07</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>9.400000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>7.000000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.960059e-11</td>\n",
       "      <td>5.370349e-11</td>\n",
       "      <td>3.837178e-11</td>\n",
       "      <td>2.275030e-11</td>\n",
       "      <td>4.715514e-11</td>\n",
       "      <td>4.289461e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>3.400000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>7.600000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200000e-07</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>6.600000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>7.751387e-11</td>\n",
       "      <td>6.390787e-11</td>\n",
       "      <td>7.703473e-11</td>\n",
       "      <td>4.169431e-11</td>\n",
       "      <td>4.903933e-11</td>\n",
       "      <td>7.545821e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.500000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>1.030000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.070000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>5.700000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>8.200000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>9.904721e-11</td>\n",
       "      <td>5.184471e-11</td>\n",
       "      <td>9.119123e-11</td>\n",
       "      <td>7.748332e-11</td>\n",
       "      <td>5.127281e-11</td>\n",
       "      <td>8.697091e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.500000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>8.300000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>7.500000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.100000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>4.700000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.170000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>5.200000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>5.222399e-11</td>\n",
       "      <td>3.696171e-11</td>\n",
       "      <td>5.159300e-11</td>\n",
       "      <td>4.482527e-11</td>\n",
       "      <td>1.616343e-11</td>\n",
       "      <td>5.393075e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9.700000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>7.200000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>2.900000e-08</td>\n",
       "      <td>1.070000e-07</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>4.300000e-08</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>1.140000e-07</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>7.192418e-11</td>\n",
       "      <td>2.853634e-11</td>\n",
       "      <td>7.038335e-11</td>\n",
       "      <td>4.771403e-11</td>\n",
       "      <td>3.345145e-11</td>\n",
       "      <td>7.201415e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.300000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>9.800000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>5.000000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>9.200000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.090000e-07</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.900000e-08</td>\n",
       "      <td>2.300000e-08</td>\n",
       "      <td>3.532088e-11</td>\n",
       "      <td>3.298135e-11</td>\n",
       "      <td>3.993382e-11</td>\n",
       "      <td>2.797669e-11</td>\n",
       "      <td>4.109851e-11</td>\n",
       "      <td>4.183354e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>7.500000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>8.800000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>9.000000e-08</td>\n",
       "      <td>3.200000e-08</td>\n",
       "      <td>1.050000e-07</td>\n",
       "      <td>2.800000e-08</td>\n",
       "      <td>7.400000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>7.763244e-11</td>\n",
       "      <td>4.690778e-11</td>\n",
       "      <td>7.584878e-11</td>\n",
       "      <td>4.302216e-11</td>\n",
       "      <td>4.350645e-11</td>\n",
       "      <td>7.718655e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3.700000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>8.800000e-08</td>\n",
       "      <td>2.400000e-08</td>\n",
       "      <td>5.800000e-08</td>\n",
       "      <td>3.100000e-08</td>\n",
       "      <td>5.100000e-08</td>\n",
       "      <td>3.000000e-08</td>\n",
       "      <td>7.300000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>7.500000e-08</td>\n",
       "      <td>2.500000e-08</td>\n",
       "      <td>2.600000e-08</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>2.624625e-11</td>\n",
       "      <td>4.042986e-11</td>\n",
       "      <td>2.244145e-11</td>\n",
       "      <td>4.042178e-11</td>\n",
       "      <td>2.860683e-11</td>\n",
       "      <td>2.353557e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             wp1           lp1           wp2           lp2           wp3  \\\n",
       "0   1.050000e-07  2.300000e-08  7.100000e-08  2.400000e-08  8.000000e-08   \n",
       "1   7.400000e-08  2.700000e-08  8.500000e-08  3.100000e-08  4.100000e-08   \n",
       "2   6.500000e-08  2.800000e-08  1.100000e-07  2.300000e-08  2.400000e-08   \n",
       "3   3.500000e-08  3.200000e-08  3.400000e-08  2.700000e-08  5.000000e-08   \n",
       "4   9.500000e-08  2.700000e-08  1.030000e-07  2.800000e-08  1.070000e-07   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "95  4.500000e-08  3.200000e-08  8.300000e-08  2.200000e-08  7.500000e-08   \n",
       "96  9.700000e-08  2.200000e-08  5.800000e-08  2.200000e-08  7.200000e-08   \n",
       "97  5.300000e-08  3.000000e-08  3.000000e-08  2.700000e-08  9.800000e-08   \n",
       "98  7.500000e-08  2.700000e-08  8.800000e-08  3.000000e-08  9.000000e-08   \n",
       "99  3.700000e-08  2.600000e-08  8.800000e-08  2.400000e-08  5.800000e-08   \n",
       "\n",
       "             lp3           wp4           lp4           wp5           lp5  ...  \\\n",
       "0   2.800000e-08  9.500000e-08  2.300000e-08  4.600000e-08  2.300000e-08  ...   \n",
       "1   3.000000e-08  9.800000e-08  3.000000e-08  1.020000e-07  2.300000e-08  ...   \n",
       "2   3.000000e-08  9.400000e-08  3.000000e-08  7.000000e-08  2.300000e-08  ...   \n",
       "3   2.700000e-08  5.800000e-08  2.700000e-08  7.600000e-08  3.000000e-08  ...   \n",
       "4   2.800000e-08  2.900000e-08  2.700000e-08  5.700000e-08  2.200000e-08  ...   \n",
       "..           ...           ...           ...           ...           ...  ...   \n",
       "95  2.300000e-08  4.100000e-08  3.100000e-08  4.700000e-08  2.500000e-08  ...   \n",
       "96  2.300000e-08  4.300000e-08  2.900000e-08  1.070000e-07  2.600000e-08  ...   \n",
       "97  2.600000e-08  5.000000e-08  2.400000e-08  9.200000e-08  2.500000e-08  ...   \n",
       "98  3.200000e-08  1.050000e-07  2.800000e-08  7.400000e-08  2.600000e-08  ...   \n",
       "99  3.100000e-08  5.100000e-08  3.000000e-08  7.300000e-08  2.700000e-08  ...   \n",
       "\n",
       "            wn13          ln13          wn14          ln14  delay_lh_nodeaco  \\\n",
       "0   4.600000e-08  2.600000e-08  1.110000e-07  2.600000e-08      2.522120e-11   \n",
       "1   7.600000e-08  2.400000e-08  3.600000e-08  2.500000e-08      5.238899e-11   \n",
       "2   1.050000e-07  2.800000e-08  1.030000e-07  3.000000e-08      3.960059e-11   \n",
       "3   1.200000e-07  3.200000e-08  6.600000e-08  2.400000e-08      7.751387e-11   \n",
       "4   2.700000e-08  3.200000e-08  8.200000e-08  2.600000e-08      9.904721e-11   \n",
       "..           ...           ...           ...           ...               ...   \n",
       "95  1.170000e-07  2.400000e-08  5.200000e-08  2.600000e-08      5.222399e-11   \n",
       "96  4.300000e-08  2.800000e-08  1.140000e-07  2.200000e-08      7.192418e-11   \n",
       "97  1.090000e-07  2.400000e-08  3.900000e-08  2.300000e-08      3.532088e-11   \n",
       "98  2.500000e-08  2.400000e-08  3.100000e-08  2.200000e-08      7.763244e-11   \n",
       "99  7.500000e-08  2.500000e-08  2.600000e-08  2.700000e-08      2.624625e-11   \n",
       "\n",
       "    delay_hl_nodeaco  delay_lh_nodebco  delay_hl_nodebco  delay_hl_nodecco  \\\n",
       "0       3.173040e-11      2.226566e-11      3.462740e-11      3.342622e-11   \n",
       "1       3.799978e-11      5.539780e-11      2.192646e-11      3.488078e-11   \n",
       "2       5.370349e-11      3.837178e-11      2.275030e-11      4.715514e-11   \n",
       "3       6.390787e-11      7.703473e-11      4.169431e-11      4.903933e-11   \n",
       "4       5.184471e-11      9.119123e-11      7.748332e-11      5.127281e-11   \n",
       "..               ...               ...               ...               ...   \n",
       "95      3.696171e-11      5.159300e-11      4.482527e-11      1.616343e-11   \n",
       "96      2.853634e-11      7.038335e-11      4.771403e-11      3.345145e-11   \n",
       "97      3.298135e-11      3.993382e-11      2.797669e-11      4.109851e-11   \n",
       "98      4.690778e-11      7.584878e-11      4.302216e-11      4.350645e-11   \n",
       "99      4.042986e-11      2.244145e-11      4.042178e-11      2.860683e-11   \n",
       "\n",
       "    delay_lh_nodecco  \n",
       "0       2.337032e-11  \n",
       "1       5.494923e-11  \n",
       "2       4.289461e-11  \n",
       "3       7.545821e-11  \n",
       "4       8.697091e-11  \n",
       "..               ...  \n",
       "95      5.393075e-11  \n",
       "96      7.201415e-11  \n",
       "97      4.183354e-11  \n",
       "98      7.718655e-11  \n",
       "99      2.353557e-11  \n",
       "\n",
       "[100 rows x 62 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'Delays_W_L_FAMIRRORSimulated_50K.xlsx'\n",
    "data = pd.read_excel(file)\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 62)\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "train = data[:40000, :]\n",
    "test = data[40000:, :]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train[:, :56]\n",
    "train_y = train[:, 56:]\n",
    "\n",
    "test_x = test[:, :56]\n",
    "test_y = test[:, 56:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 56)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(train_x, dtype=torch.float) \n",
    "y = torch.tensor(train_y[:,0], dtype=torch.float) \n",
    "xPredicted = torch.tensor(test_x, dtype=torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40000, 56])\n",
      "torch.Size([40000])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        \n",
    "        self.inputSize = 56\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 28\n",
    "        \n",
    "        self.W1 = torch.randn(self.inputSize, self.hiddenSize) \n",
    "        self.W2 = torch.randn(self.hiddenSize, self.outputSize) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.z = torch.matmul(X, self.W1) \n",
    "        self.z2 = self.sigmoid(self.z) \n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3) \n",
    "        return o\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o \n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o) \n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        \n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        \n",
    "        torch.save(model, \"NN\")\n",
    "        \n",
    "        # torch.load(\"NN\")\n",
    "        \n",
    "    def predict(self):\n",
    "        print (\"Predicted data based on trained weights: \")\n",
    "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
    "        print (\"Output: \\n\" + str(self.forward(xPredicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "NN = Neural_Network()\n",
    "for i in range(1):  \n",
    "    if (i % 1) == 0:\n",
    "        print(i)\n",
    "        print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(X, y)\n",
    "NN.saveWeights(NN)\n",
    "NN.predict()\n",
    "\n",
    "print(\"Finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
